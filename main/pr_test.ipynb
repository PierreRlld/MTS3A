{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/!\\ **fredpy python api is needed to fork data, requires FRED_API_KEY=\"your_api_key\" in file .zshrc and .bashrc** /!\\\n",
    "\n",
    "- Making a request for a key : https://fred.stlouisfed.org/docs/api/api_key.html\n",
    "- Possibly add FRED_API_KEY=\"your_api_key\" in files .zshrc and .bashrc of computer if code cannot run\n",
    "- Otherwise try (,api_key=\"my_api_key\") in .get_series of function fred_data\n",
    "- **Otherwise the data is saved in \"data_save.csv\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "import pyfredapi as pf\n",
    "import MacroRandomForest as MRF\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "from math import *\n",
    "\n",
    "# Use matplotlib's 'classic' style, set figure facecolor to white\n",
    "plt.style.use('classic')\n",
    "plt.rcParams.update({'figure.facecolor': 'white'})\n",
    "matplotlib.rcParams['figure.figsize'] = [20, 9]\n",
    "\n",
    "global start_date, end_date, window_dates\n",
    "start_date = np.datetime64('1980-01-01')\n",
    "end_date = np.datetime64('2023-12-01')\n",
    "\n",
    "\n",
    "start_covid = np.datetime64('2020-01-01')\n",
    "end_covid = np.datetime64(\"2021-04-01\")\n",
    "\n",
    "start_gfc = np.datetime64(\"2007-05-01\")\n",
    "end_gfc = np.datetime64(\"2009-02-01\")\n",
    "\n",
    "\n",
    "current_date = start_date\n",
    "window_dates = []\n",
    "\n",
    "while current_date <= end_date:\n",
    "    window_dates.append(current_date)\n",
    "    current_date = np.datetime64(current_date, 'M') + np.timedelta64(1, 'M')\n",
    "\n",
    "window_dates = np.array(window_dates, dtype='datetime64[M]').tolist()\n",
    "\n",
    "gdpm = pd.read_excel(\"US-Monthly-GDP-History-Data.xlsx\",sheet_name=\"Data\")\n",
    "gdpm.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "gdpm.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supp = pd.read_csv(\"fred_data_new_stat.csv\")\n",
    "df_supp.rename(columns={\"Unnamed: 0\":\"dates\"},inplace=True)\n",
    "df_supp.set_index(\"dates\",drop=True,inplace=True)\n",
    "df_supp.index.name= None\n",
    "df_supp.index = pd.to_datetime(df_supp.index)\n",
    "display(df_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requested series\n",
    "REQUEST_LIST = [\"CSUSHPISA\",\"FEDFUNDS\",\"DGS10\",\"MORTGAGE30US\",\"REAINTRATREARAT10Y\",\"PSAVERT\",\n",
    "                  \"CURRCIR\",\"M2SL\",\"INDPRO\",\"UNRATE\",\"CIVPART\",\"CPIAUCSL\",\"MICH\",\n",
    "                  \"PCE\",\"DSPIC96\",\"TTLHHM156N\",\"TOTALSL\",\"DPSACBW027SBOG\",\"MSACSR\"]\n",
    "\n",
    "def fred_data(L:list):\n",
    "    x = pd.DataFrame(columns=L, index=window_dates)\n",
    "    \n",
    "    with tqdm(total=len(L), ascii=True) as pbar:\n",
    "        for var in L:\n",
    "            try:\n",
    "                y = pf.get_series(series_id=var,observation_start=str(start_date),observation_end=str(end_date),frequency=\"m\")\n",
    "                \n",
    "                # ===== EDIT HERE IN CASE NEEDED - see comment on fred api at the beginning - edit \"my_api_key\" with FRED provided api key\n",
    "                #y = pf.get_series(api_key=\"my_api_key\",series_id=var,observation_start=str(start_date),observation_end=str(end_date),frequency=\"m\")\n",
    "                # ===========================================================================\n",
    "                \n",
    "                y.set_index('date',inplace=True)\n",
    "                y.drop(columns=[\"realtime_start\",\"realtime_end\"],inplace=True)\n",
    "                x[var] = y.value\n",
    "            except:\n",
    "                None\n",
    "            pbar.update()\n",
    "    x['SPREAD'] = x['DGS10'] - x['FEDFUNDS']\n",
    "    x = x.drop(columns=[\"FEDFUNDS\",\"DGS10\"])\n",
    "    return x\n",
    "\n",
    "#TODO: data request\n",
    "data = fred_data(L=REQUEST_LIST)\n",
    "data[['GDPn','GDPr']] = gdpm[['GDPn','GDPr']] # Monthly GDP data import\n",
    "\n",
    "# Indicatrices (was not useful)\n",
    "data['GFC'] = data.index\n",
    "data['GFC'] = data['GFC'].apply(lambda x: start_gfc<= x <= end_gfc).apply(lambda x: x*1)\n",
    "data['Covid'] = data.index\n",
    "data['Covid'] = data['Covid'].apply(lambda x: start_covid<= x <= end_covid).apply(lambda x: x*1)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "display(data)\n",
    "#data.to_csv(\"Data_save.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation & transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- \n",
    "#TODO: usual transformation for stationarity \n",
    "#? \"diff_ln\" : 100*(log(x_'t') - log(x_'t-12')) = YoY growth rate\n",
    "#? \"diff\" : 100*(x_'t' - x_'t-12') = YoY change in ... rate\n",
    "#? rolling : special case of \"MSACSR\" : at time t it is the YoY% growth rate between : the number of houses added between (t) and (t)-11 (= over the past year) and the same number but between (t-12) and (t-12)-11 \n",
    "#? \"level\" : no change on data\n",
    "\n",
    "DATA_TRANSFORM = {\n",
    "\"diff_ln\":[\n",
    "\"CSUSHPISA\",\n",
    "\"CURRCIR\",\n",
    "\"M2SL\",\n",
    "\"CPIAUCSL\",\n",
    "\"INDPRO\",\n",
    "\"PCE\",\n",
    "\"DSPIC96\",\n",
    "\"TTLHHM156N\",\n",
    "\"TOTALSL\",\n",
    "\"DPSACBW027SBOG\",\n",
    "\"GDPr\"\n",
    "],\n",
    "\n",
    "\"diff\":[\n",
    "\"MORTGAGE30US\",\n",
    "\"REAINTRATREARAT10Y\",\n",
    "\"UNRATE\",\n",
    "\"CIVPART\",\n",
    "\"MICH\"\n",
    "],\n",
    "\n",
    "\"level\":[\n",
    "\"SPREAD\",\n",
    "\"PSAVERT\"\n",
    "],\n",
    "\n",
    "\"rolling\":[\"MSACSR\"]\n",
    "}\n",
    "\n",
    "def log_transform(cell_value):\n",
    "    try:\n",
    "        return np.log(float(cell_value))\n",
    "    except (ValueError, TypeError):\n",
    "        return cell_value\n",
    "\n",
    "def data_treat(df,treatment):\n",
    "        \n",
    "    x = pd.DataFrame(index=df.index)\n",
    "    for key in treatment:\n",
    "        if key==\"diff_ln\":\n",
    "            x[treatment[key]] = 100*df[treatment[key]].applymap(log_transform).diff(periods=12)\n",
    "        elif key==\"diff\":\n",
    "            x[treatment[key]] = df[treatment[key]].diff(periods=1)\n",
    "        elif key==\"level\":\n",
    "            x[treatment[key]] = df[treatment[key]]\n",
    "        else:\n",
    "            x[treatment[key]] = 100*df[treatment[key]].rolling(12).sum().pct_change(periods=12)\n",
    "    x = x.dropna()\n",
    "    return x\n",
    "\n",
    "df_data = data_treat(df=data,treatment=DATA_TRANSFORM)\n",
    "VARIABLES_LIST = list(df_data.columns)[1::]\n",
    "#df_data = df_data - df_data.mean()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- #\n",
    "\n",
    "#* Steps ahead forecast\n",
    "for k in [1,3,6,12]:\n",
    "    df_data[f\"CSUSHPISA+{k}\"] = df_data[\"CSUSHPISA\"].shift(periods=-k)\n",
    "\n",
    "#* > lags [1:3] of all variables\n",
    "for k in range(1,len(VARIABLES_LIST)):\n",
    "    if VARIABLES_LIST[k] in ['GFC','Covid']:\n",
    "        pass\n",
    "    else:\n",
    "        for i in range(1,4):\n",
    "            df_data[f\"{VARIABLES_LIST[k]}-{i}\"] = df_data[f\"{VARIABLES_LIST[k]}\"].shift(periods=i)\n",
    "\n",
    "#* > Lags of dependent variable : up to ...\n",
    "for k in range(1,4):\n",
    "    df_data[f\"CSUSHPISA-{k}\"] = df_data[\"CSUSHPISA\"].shift(periods=k)\n",
    "    \n",
    "df_data = df_data.dropna()\n",
    "df_data = pd.concat([df_data,df_supp],axis=1,join=\"inner\")\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTATS = {\"CSUSHPISA+1\":pd.DataFrame(index=df_data.index),\"CSUSHPISA+3\":pd.DataFrame(index=df_data.index),\"CSUSHPISA+6\":pd.DataFrame(index=df_data.index),\"CSUSHPISA+12\":pd.DataFrame(index=df_data.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================================ #\n",
    "#! Based on experience when changing any Y_VAR / X_VAR it is better to restart the kernel an re-run all the code until here to avoid any wrongdoing of the following training bloc - save comments later on\n",
    "\n",
    "#* -----------------------\n",
    "###* Dependent Variable\n",
    "\n",
    "#? (1) One-step ahead\n",
    "#Y_VAR = \"CSUSHPISA+1\"  \n",
    "\n",
    "#? (2) 3-step ahead\n",
    "#Y_VAR = \"CSUSHPISA+3\"\n",
    "\n",
    "#? (3) 6-step ahead\n",
    "Y_VAR = \"CSUSHPISA+6\"\n",
    "\n",
    "\n",
    "#* -----------------------\n",
    "###* Linear part\n",
    "#? (1) Baseline\n",
    "#X_VAR = [\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"]\n",
    "\n",
    "#? (2) Baseline AR\n",
    "X_VAR = [\"CSUSHPISA\",\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"]\n",
    "\n",
    "#? (2) 2-Lag AR\n",
    "#X_VAR = [\"CSUSHPISA\",\"CSUSHPISA-1\",\"CSUSHPISA-2\"]\n",
    "\n",
    "\n",
    "#* -----------------------\n",
    "###* Exogenous Variables\n",
    "\n",
    "#? (1) S_t\n",
    "#S_VAR = [\"CSUSHPISA\",\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"]\n",
    "\n",
    "#? (2) S_t[0-2]\n",
    "#svari = [\"CSUSHPISA\",\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"]\n",
    "#S_VAR = svari + [f\"{var}-{i}\" for var in svari for i in range(1,3)]\n",
    "\n",
    "#? (3)\n",
    "S_VAR = [\"CSUSHPISA\",\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"] + list(df_supp.columns)\n",
    "\n",
    "\n",
    "# ================================== #\n",
    "# ================================== #\n",
    "# Data for the MRF training\n",
    "data_MRF = pd.DataFrame(index = df_data.index)\n",
    "data_MRF[[Y_VAR]] = df_data[[Y_VAR]].copy()\n",
    "data_MRF[X_VAR] = df_data[X_VAR].copy()\n",
    "data_MRF[S_VAR] = df_data[S_VAR].copy()\n",
    "data_MRF.T.drop_duplicates().T          #drop duplicate columns if any\n",
    "Y_pos = data_MRF.columns.get_loc(Y_VAR)\n",
    "S_pos = [data_MRF.columns.get_loc(s) for s in S_VAR]\n",
    "X_pos = [data_MRF.columns.get_loc(x) for x in X_VAR]\n",
    "# ================================== #\n",
    "# ================================== #\n",
    "\n",
    "\n",
    "# ======= OOS-WINDOW ============== #\n",
    "K_OOS = 48\n",
    "oos_pos = np.arange(len(data_MRF) - K_OOS, len(data_MRF))\n",
    "\n",
    "# ======= RESULTS ================ #\n",
    "RESULTATS[Y_VAR]['actual'] = np.nan\n",
    "RESULTATS[Y_VAR]['actual'].iloc[oos_pos] = df_data[Y_VAR].iloc[oos_pos]\n",
    "\n",
    "# ================================================================================================ #\n",
    "display(data_MRF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_MRF.iloc[oos_pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial comments on some code errors\n",
    "\n",
    "**If the oos-forecast show too extreme variations / really high spikes and trough for a few months / flat lines : re-run whole code by restarting kernel**\n",
    "\n",
    "As the process is highly ressource-intensive it appears that when the computer struggles in the forecast phase (especially when the notebook had already been ran) - points are missing and generate abnomrmal spikes/flat lines.\n",
    "See below for example:\n",
    "\n",
    "This generates those type of odd results, not due to model miss specification or anything but just due to how the MRF package seem to handle computer struggle.\n",
    "Reseting the python kernel to run another model seem to solve this problem in most cases.\n",
    "\n",
    "<div>\n",
    "<img src=\"computer_struggle2.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "When we look at the predicted coefficients from the MRF some forecasted points are indeed missing, causing the flat lines some are missing for successive dates or a trough when it is a single date missing... \n",
    "Only solution is to re-run the code\n",
    "\n",
    "<div>\n",
    "<img src=\"computer_struggle.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "For reference this is the correct output (without computer struggle induced missing values).\n",
    "\n",
    "<div>\n",
    "<img src=\"computer_struggle3.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================== #\n",
    "#TODO: /// MRF FIT ///\n",
    "MRF_model = MRF.MacroRandomForest(data = data_MRF.copy(),\n",
    "            y_pos = Y_pos,\n",
    "            x_pos = X_pos,\n",
    "            S_pos = S_pos,\n",
    "            mtry_frac=0.75,\n",
    "            B = 1000,\n",
    "            parallelise = True,\n",
    "            n_cores = -1,\n",
    "            resampling_opt = 2,\n",
    "            oos_pos = oos_pos,\n",
    "            trend_push = 4,\n",
    "            quantile_rate=None,\n",
    "            ridge_lambda=0.001,\n",
    "            subsampling_rate=0.65,\n",
    "            rw_regul=0.75,\n",
    "            print_b = True,\n",
    "            fast_rw = True)\n",
    "\n",
    "# ================================== #\n",
    "#TODO: /// MRF training ///\n",
    "MRF_output = MRF_model._ensemble_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display time-varying parameters\n",
    "MRF_model.band_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute results\n",
    "beta_res = pd.DataFrame(MRF_output['betas'],index=data_MRF.index,columns=['const']+X_VAR)\n",
    "fit_res = pd.DataFrame(index=beta_res.index)\n",
    "for x in X_VAR:\n",
    "    fit_res[x] = beta_res[x]*df_data[x]\n",
    "fit_res['const'] = beta_res['const']\n",
    "\n",
    "fit_res['training'] = fit_res.sum(axis=1)\n",
    "fit_res['oos'] = fit_res['training']\n",
    "fit_res['training'].iloc[oos_pos] = np.nan\n",
    "fit_res['oos'].iloc[:len(fit_res)-len(oos_pos)] = np.nan\n",
    "fit_res['actual'] = df_data[Y_VAR]\n",
    "fit_res\n",
    "\n",
    "RESULTATS[Y_VAR]['OOS'] = fit_res['oos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_res.tail(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fit_res[['training','oos','actual']].plot(color=['blue','red','black']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_true=RESULTATS[Y_VAR].iloc[oos_pos][\"actual\"],y_pred=RESULTATS[Y_VAR].iloc[oos_pos][\"OOS\"]))\n",
    "print(sqrt(mean_squared_error(y_true=RESULTATS[Y_VAR].iloc[oos_pos][\"actual\"],y_pred=RESULTATS[Y_VAR].iloc[oos_pos][\"OOS\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_res[[\"oos\",\"actual\"]].iloc[oos_pos].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_VAR = \"CSUSHPISA+3\"\n",
    "#Y_VAR = \"CSUSHPISA+6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataForClassificationRF(dataset,x_reg,y_reg,oos=48):\n",
    "    \"\"\"\n",
    "    generates categorical output column, which is then used\n",
    "    to create the train and test data\n",
    "    \"\"\" \n",
    "    dataset_rf = dataset.copy().reset_index()\n",
    "    X = (dataset_rf[x_reg])\n",
    "    y = (dataset_rf[y_reg])\n",
    "    \n",
    "    X_train = X.iloc[0:len(X) - oos]\n",
    "    y_train = y.iloc[0:len(y) - oos]\n",
    "    \n",
    "    X_test = X.iloc[len(X) - oos::]\n",
    "    y_test = y.iloc[len(y) - oos::]\n",
    "    \n",
    "    train_index, test_index = dataset.index[0:len(X) - oos], dataset.index[len(X) - oos::]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, train_index, test_index, dataset\n",
    "\n",
    "#rfbase = [\"CSUSHPISA\",\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"] # [X,HP]_t \n",
    "rfbase = [\"CSUSHPISA\"]\n",
    "xvar_rf = rfbase + [f\"{var}-{i}\" for var in rfbase for i in range(1,3)]\n",
    "#xvar_rf = [\"CSUSHPISA\",\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"]\n",
    "#xvar_rf = [\"CPIAUCSL\",\"DSPIC96\",\"SPREAD\",\"MORTGAGE30US\",\"UNRATE\"]\n",
    "\n",
    "X_train, y_train, X_test, y_test, train_index, test_index, dataset  = prepareDataForClassificationRF(dataset=df_data,x_reg=xvar_rf,y_reg=Y_VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Model = RandomForestRegressor(n_estimators=1000,\n",
    "                                 max_features=0.60, oob_score=False,\n",
    "                                 min_samples_split=20)\n",
    "labels = y_train\n",
    "features = X_train\n",
    "rgr=RF_Model.fit(features, labels)\n",
    "X_test_predict=pd.DataFrame(rgr.predict(X_test), index=test_index)\n",
    "X_train_predict=pd.DataFrame(rgr.predict(X_train), index=train_index)\n",
    "RF_predict = X_train_predict.append(X_test_predict).rename(columns={0:'plain_RF_predict'})\n",
    "RF_predict['actual'] = df_data[Y_VAR].copy()\n",
    "print(\"R2_score : \",r2_score(y_true=RF_predict.iloc[oos_pos]['actual'],y_pred=RF_predict.iloc[oos_pos]['plain_RF_predict']))\n",
    "\n",
    "RF_predict_result = pd.DataFrame(index=RF_predict.index)\n",
    "RF_predict_result[[\"training\",\"oos\",\"actual\"]] = \"\"\n",
    "RF_predict_result[\"training\"].iloc[:len(RF_predict_result)-48] = RF_predict[\"plain_RF_predict\"].iloc[:len(RF_predict_result)-48]\n",
    "RF_predict_result[\"training\"].iloc[len(RF_predict_result)-48::] = np.nan\n",
    "RF_predict_result[\"oos\"].iloc[len(RF_predict_result)-48::] = RF_predict[\"plain_RF_predict\"].iloc[len(RF_predict_result)-48::]\n",
    "RF_predict_result[\"oos\"].iloc[:len(RF_predict_result)-48] = np.nan\n",
    "RF_predict_result[\"actual\"] = RF_predict[\"actual\"]\n",
    "RF_predict_result.plot(color=['blue','red','black'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mts3a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
